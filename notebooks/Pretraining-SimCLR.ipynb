{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, Callback\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Dataset với sanity-check\n",
    "# -----------------------------------\n",
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        assert not self.data.empty, f\"CSV {csv_file} is empty!\"\n",
    "        \n",
    "        # Chuyển đổi tất cả đường dẫn trong cột 'file' thành đường dẫn tuyệt đối\n",
    "        self.data['file'] = self.data['file'].apply(os.path.abspath)\n",
    "        \n",
    "        # Kiểm tra sự tồn tại của 5 file đầu tiên (tùy chọn)\n",
    "        for p in self.data['file'].iloc[:5]:\n",
    "            assert os.path.isfile(p), f\"File not found: {p}\"\n",
    "        \n",
    "        print(f\"✅ Loaded {len(self.data)} samples from {csv_file}\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['file']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        xi = self.transform(image)\n",
    "        xj = self.transform(image)\n",
    "        return xi, xj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) SimCLR LightningModule\n",
    "# -----------------------------------\n",
    "class SimCLR(pl.LightningModule):\n",
    "    def __init__(self, temperature=0.5, lr=1e-3):\n",
    "        super().__init__()\n",
    "        torch.set_float32_matmul_precision('medium')\n",
    "        self.temperature = temperature\n",
    "        self.lr = lr\n",
    "\n",
    "        # Encoder\n",
    "        backbone = resnet18(weights=None)\n",
    "        num_ftrs = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.encoder = backbone\n",
    "\n",
    "        # Projection head\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self.projector(h)\n",
    "        return F.normalize(z, dim=1)\n",
    "\n",
    "    def info_nce_loss(self, z):\n",
    "        batch_size = z.shape[0] // 2\n",
    "        z = F.normalize(z, dim=1)\n",
    "        sim = torch.matmul(z, z.T) / self.temperature\n",
    "        mask = torch.eye(batch_size * 2, device=z.device).bool()\n",
    "        sim = sim.masked_fill(mask, -9e15)\n",
    "\n",
    "        positives = torch.cat([\n",
    "            sim[i, i + batch_size].unsqueeze(0)\n",
    "            for i in range(batch_size)\n",
    "        ] + [\n",
    "            sim[i + batch_size, i].unsqueeze(0)\n",
    "            for i in range(batch_size)\n",
    "        ], dim=0)\n",
    "        numerator = torch.exp(positives)\n",
    "\n",
    "        denominator = torch.exp(sim).sum(dim=1)\n",
    "        loss = -torch.log(numerator / denominator).mean()\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xi, xj = batch\n",
    "        x = torch.cat([xi, xj], dim=0)\n",
    "        z = self(x)\n",
    "        loss = self.info_nce_loss(z)\n",
    "        # Sanity print first few steps\n",
    "        if batch_idx == 0 and self.current_epoch == 0:\n",
    "            print(f\">>> [Debug] First loss = {loss.item():.4f}\")\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Callback để in epoch bắt đầu\n",
    "# -----------------------------------\n",
    "class EpochPrintCallback(Callback):\n",
    "    def on_train_epoch_start(self, trainer, pl_module):\n",
    "        print(f\"\\n>>> Starting Epoch {trainer.current_epoch+1}/{trainer.max_epochs} at {time.time():.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 10015 samples from ../data/isic2018/labels/train_unlabeled.csv\n"
     ]
    }
   ],
   "source": [
    "# 4) Transforms & DataLoader\n",
    "# -----------------------------------\n",
    "simclr_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.8,0.8,0.8,0.2)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = SimCLRDataset(\n",
    "    csv_file='../data/isic2018/labels/train_unlabeled.csv',\n",
    "    transform=simclr_transform\n",
    ")\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Using device: cuda\n",
      "Parameter device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = SimCLR().to(device)\n",
    "# Kiểm tra tham số đầu tiên\n",
    "p = next(model.parameters())\n",
    "print(\"Parameter device:\", p.device)   # phải in cuda:0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "Step time: 12.569s, loss=5.5300\n",
      "Model device: cuda:0\n",
      "Data device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time, torch\n",
    "# 1) Kiểm tra GPU\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2) Dummy data loader\n",
    "batch = next(iter(loader))  # loader đã được tạo như trước\n",
    "xi, xj = batch\n",
    "xi = xi.to(device)\n",
    "xj = xj.to(device)\n",
    "\n",
    "# 3) Forward + loss\n",
    "model = SimCLR().to(device)\n",
    "start = time.time()\n",
    "z = model(torch.cat([xi, xj], dim=0))\n",
    "loss = model.info_nce_loss(z)\n",
    "loss.backward()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Step time: {end-start:.3f}s, loss={loss.item():.4f}\")\n",
    "print(\"Model device:\", next(model.parameters()).device)\n",
    "print(\"Data device:\", xi.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder   | ResNet     | 11.2 M | train\n",
      "1 | projector | Sequential | 164 K  | train\n",
      "-------------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.363    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\user\\miniconda3\\envs\\MLF-CoDA-Project\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e4076b1ae645d88180ccf8d8b27a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Starting Epoch 1/100 at 1748329725.7s\n",
      ">>> [Debug] First loss = 5.5302\n",
      "\n",
      ">>> Starting Epoch 2/100 at 1748331010.3s\n",
      "\n",
      ">>> Starting Epoch 3/100 at 1748332301.0s\n",
      "\n",
      ">>> Starting Epoch 4/100 at 1748333707.9s\n",
      "\n",
      ">>> Starting Epoch 5/100 at 1748335058.2s\n",
      "\n",
      ">>> Starting Epoch 6/100 at 1748336358.2s\n",
      "\n",
      ">>> Starting Epoch 7/100 at 1748337658.3s\n",
      "\n",
      ">>> Starting Epoch 8/100 at 1748338948.0s\n",
      "\n",
      ">>> Starting Epoch 9/100 at 1748340285.7s\n",
      "\n",
      ">>> Starting Epoch 10/100 at 1748341629.4s\n",
      "\n",
      ">>> Starting Epoch 11/100 at 1748342978.4s\n",
      "\n",
      ">>> Starting Epoch 12/100 at 1748344405.6s\n",
      "\n",
      ">>> Starting Epoch 13/100 at 1748345758.5s\n",
      "\n",
      ">>> Starting Epoch 14/100 at 1748347064.1s\n",
      "\n",
      ">>> Starting Epoch 15/100 at 1748348373.2s\n",
      "\n",
      ">>> Starting Epoch 16/100 at 1748349644.4s\n",
      "\n",
      ">>> Starting Epoch 17/100 at 1748350995.9s\n",
      "\n",
      ">>> Starting Epoch 18/100 at 1748352278.2s\n",
      "\n",
      ">>> Starting Epoch 19/100 at 1748353587.9s\n",
      "\n",
      ">>> Starting Epoch 20/100 at 1748354921.7s\n",
      "\n",
      ">>> Starting Epoch 21/100 at 1748356247.1s\n",
      "\n",
      ">>> Starting Epoch 22/100 at 1748357678.4s\n",
      "\n",
      ">>> Starting Epoch 23/100 at 1748359155.6s\n",
      "\n",
      ">>> Starting Epoch 24/100 at 1748360525.3s\n",
      "\n",
      ">>> Starting Epoch 25/100 at 1748361865.2s\n",
      "\n",
      ">>> Starting Epoch 26/100 at 1748363206.9s\n",
      "\n",
      ">>> Starting Epoch 27/100 at 1748364506.8s\n",
      "\n",
      ">>> Starting Epoch 28/100 at 1748365779.5s\n",
      "\n",
      ">>> Starting Epoch 29/100 at 1748367043.9s\n",
      "\n",
      ">>> Starting Epoch 30/100 at 1748368307.5s\n",
      "\n",
      ">>> Starting Epoch 31/100 at 1748369570.6s\n",
      "\n",
      ">>> Starting Epoch 32/100 at 1748370835.6s\n",
      "\n",
      ">>> Starting Epoch 33/100 at 1748372100.2s\n",
      "\n",
      ">>> Starting Epoch 34/100 at 1748373364.5s\n",
      "\n",
      ">>> Starting Epoch 35/100 at 1748374628.3s\n",
      "\n",
      ">>> Starting Epoch 36/100 at 1748375893.5s\n",
      "\n",
      ">>> Starting Epoch 37/100 at 1748377157.3s\n",
      "\n",
      ">>> Starting Epoch 38/100 at 1748378422.5s\n",
      "\n",
      ">>> Starting Epoch 39/100 at 1748379689.0s\n",
      "\n",
      ">>> Starting Epoch 40/100 at 1748380953.4s\n",
      "\n",
      ">>> Starting Epoch 41/100 at 1748382218.9s\n",
      "\n",
      ">>> Starting Epoch 42/100 at 1748383484.5s\n",
      "\n",
      ">>> Starting Epoch 43/100 at 1748384750.0s\n",
      "\n",
      ">>> Starting Epoch 44/100 at 1748386016.7s\n",
      "\n",
      ">>> Starting Epoch 45/100 at 1748387283.0s\n",
      "\n",
      ">>> Starting Epoch 46/100 at 1748388549.1s\n",
      "\n",
      ">>> Starting Epoch 47/100 at 1748389815.9s\n",
      "\n",
      ">>> Starting Epoch 48/100 at 1748391083.3s\n",
      "\n",
      ">>> Starting Epoch 49/100 at 1748392371.2s\n",
      "\n",
      ">>> Starting Epoch 50/100 at 1748393662.0s\n",
      "\n",
      ">>> Starting Epoch 51/100 at 1748394952.3s\n",
      "\n",
      ">>> Starting Epoch 52/100 at 1748396242.8s\n",
      "\n",
      ">>> Starting Epoch 53/100 at 1748397534.4s\n",
      "\n",
      ">>> Starting Epoch 54/100 at 1748398887.5s\n",
      "\n",
      ">>> Starting Epoch 55/100 at 1748400185.8s\n",
      "\n",
      ">>> Starting Epoch 56/100 at 1748401672.4s\n",
      "\n",
      ">>> Starting Epoch 57/100 at 1748403100.5s\n",
      "\n",
      ">>> Starting Epoch 58/100 at 1748404441.4s\n",
      "\n",
      ">>> Starting Epoch 59/100 at 1748405772.6s\n",
      "\n",
      ">>> Starting Epoch 60/100 at 1748407200.4s\n",
      "\n",
      ">>> Starting Epoch 61/100 at 1748408503.0s\n",
      "\n",
      ">>> Starting Epoch 62/100 at 1748409805.1s\n",
      "\n",
      ">>> Starting Epoch 63/100 at 1748411107.7s\n",
      "\n",
      ">>> Starting Epoch 64/100 at 1748412409.7s\n",
      "\n",
      ">>> Starting Epoch 65/100 at 1748413711.6s\n",
      "\n",
      ">>> Starting Epoch 66/100 at 1748415014.5s\n",
      "\n",
      ">>> Starting Epoch 67/100 at 1748416319.4s\n",
      "\n",
      ">>> Starting Epoch 68/100 at 1748417618.8s\n",
      "\n",
      ">>> Starting Epoch 69/100 at 1748419074.7s\n",
      "\n",
      ">>> Starting Epoch 70/100 at 1748420549.3s\n",
      "\n",
      ">>> Starting Epoch 71/100 at 1748421880.6s\n",
      "\n",
      ">>> Starting Epoch 72/100 at 1748423215.9s\n",
      "\n",
      ">>> Starting Epoch 73/100 at 1748424597.2s\n",
      "\n",
      ">>> Starting Epoch 74/100 at 1748426078.5s\n",
      "\n",
      ">>> Starting Epoch 75/100 at 1748427457.5s\n",
      "\n",
      ">>> Starting Epoch 76/100 at 1748428780.8s\n",
      "\n",
      ">>> Starting Epoch 77/100 at 1748430102.1s\n",
      "\n",
      ">>> Starting Epoch 78/100 at 1748431424.6s\n",
      "\n",
      ">>> Starting Epoch 79/100 at 1748432746.0s\n",
      "\n",
      ">>> Starting Epoch 80/100 at 1748434067.1s\n",
      "\n",
      ">>> Starting Epoch 81/100 at 1748435397.3s\n",
      "\n",
      ">>> Starting Epoch 82/100 at 1748436735.7s\n",
      "\n",
      ">>> Starting Epoch 83/100 at 1748438074.9s\n",
      "\n",
      ">>> Starting Epoch 84/100 at 1748439415.1s\n",
      "\n",
      ">>> Starting Epoch 85/100 at 1748440756.3s\n",
      "\n",
      ">>> Starting Epoch 86/100 at 1748442094.3s\n",
      "\n",
      ">>> Starting Epoch 87/100 at 1748443434.3s\n",
      "\n",
      ">>> Starting Epoch 88/100 at 1748444836.6s\n",
      "\n",
      ">>> Starting Epoch 89/100 at 1748446253.3s\n",
      "\n",
      ">>> Starting Epoch 90/100 at 1748447701.3s\n",
      "\n",
      ">>> Starting Epoch 91/100 at 1748449120.4s\n",
      "\n",
      ">>> Starting Epoch 92/100 at 1748450572.5s\n",
      "\n",
      ">>> Starting Epoch 93/100 at 1748451993.0s\n",
      "\n",
      ">>> Starting Epoch 94/100 at 1748453334.4s\n",
      "\n",
      ">>> Starting Epoch 95/100 at 1748454695.7s\n",
      "\n",
      ">>> Starting Epoch 96/100 at 1748456054.9s\n",
      "\n",
      ">>> Starting Epoch 97/100 at 1748457416.2s\n",
      "\n",
      ">>> Starting Epoch 98/100 at 1748458778.2s\n",
      "\n",
      ">>> Starting Epoch 99/100 at 1748460133.0s\n",
      "\n",
      ">>> Starting Epoch 100/100 at 1748461495.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "# 5) Trainer & Fit\n",
    "# -----------------------------------\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    callbacks=[\n",
    "        TQDMProgressBar(refresh_rate=1),\n",
    "        EpochPrintCallback()\n",
    "    ],\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True,\n",
    ")\n",
    "\n",
    "model = SimCLR()\n",
    "trainer.fit(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.encoder.state_dict(), \"../checkpoints/simclr_encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.projector.state_dict(), \"../checkoints/simclr_projector.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLF-CoDA-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
